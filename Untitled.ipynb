{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CarND-Behavioral-Cloning-P3\n",
    "# Udacity Self Driving Car Nanodegree - Behavioral Cloning\n",
    "\n",
    "# Installation\n",
    "To create an environment for this project use the following command:\n",
    "\n",
    "\n",
    "conda env create -f environment.yml\n",
    "\n",
    "\n",
    "After the environment is created, it needs to be activated with the command:\n",
    "\n",
    "source activate self_drive (env name)\n",
    "\n",
    "# Project\n",
    "\n",
    "## Goals\n",
    "\n",
    "The goals/steps of this project are the following:\n",
    "\n",
    "- Use the simulator to collect data of good driving behavior.\n",
    "- Build, a convolution neural network in [Keras](https://keras.io/) that predicts steering angles from images.\n",
    "- Train and validate the model with a training and validation set.\n",
    "- Test that the model successfully drives around track one without leaving the road.\n",
    "- Summarize the results with a written report.\n",
    "\n",
    "## Rubric points\n",
    "\n",
    "Here I will consider the [rubric points](https://review.udacity.com/#!/rubrics/432/view) individually and describe how I addressed each point in my implementation.\n",
    "\n",
    "### Files Submitted & Code Quality\n",
    "\n",
    "#### 1. Submission includes all required files and can be used to run the simulator in autonomous mode\n",
    "My project includes the following files:\n",
    "\n",
    "- **model.py** : Containing the script to create and train the model\n",
    "- **drive.py** : For driving the car in autonomous mode in the simulator \n",
    "- **writeup_report.md** : Summarizing the results\n",
    "- **run1.mpy** : video sample\n",
    "\n",
    "Node:\n",
    "\n",
    "On my first iteration, I tried [LeNet](http://yann.lecun.com/exdb/lenet/) model and [nVidia Autonomous Car Group](https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/) model\n",
    "\n",
    "#### 2. Submission includes functional code Using the Udacity provided simulator and my drive.py file; the car can be driven autonomously around the track by executing\n",
    "\n",
    "```\n",
    "Python drive.py model.h5\n",
    "```\n",
    "\n",
    "#### 3. Submission code is usable and readable\n",
    "\n",
    "The model.py file contains the code for training and saving the convolution neural network. The file shows the pipeline I used for training and validating the model, and it contains comments to explain how the code works.\n",
    "\n",
    "### Model Architecture and Training Strategy\n",
    "\n",
    "#### 1. An appropriate model architecture has been employed\n",
    "\n",
    "My initial approach was to use [LeNet](http://yann.lecun.com/exdb/lenet/), but it was hard to have the car inside the street with three epochs. After this, I decided to try the [nVidia Autonomous Car Group](https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/) model, and the car drove the complete first track after just three training epochs.\n",
    "\n",
    "A model summary is as follows:\n",
    "\n",
    "```\n",
    "Layer (type)                                  Connected to                     \n",
    "====================================================================================================\n",
    "lambda_1 (Lambda)              |    lambda_input_2[0][0]             \n",
    "_______________________________|_____________________________________________________________________\n",
    "cropping2d_1 (Cropping2D)      |    lambda_1[0][0]                   \n",
    "_______________________________|_____________________________________________________________________\n",
    "convolution2d_1 (Convolution2D)|    cropping2d_1[0][0]               \n",
    "_______________________________|_____________________________________________________________________\n",
    "convolution2d_2 (Convolution2D)|    convolution2d_1[0][0]            \n",
    "_______________________________|_____________________________________________________________________\n",
    "Dropout                        |    convolution2d_2[0][0]\n",
    "_______________________________|______________________________________________________________________\n",
    "convolution2d_3 (Convolution2D)|    Dropout            \n",
    "_______________________________|_____________________________________________________________________\n",
    "convolution2d_4 (Convolution2D)|    convolution2d_3[0][0]            \n",
    "_______________________________|_____________________________________________________________________\n",
    "convolution2d_5 (Convolution2D)|    convolution2d_4[0][0]            \n",
    "_______________________________|_____________________________________________________________________\n",
    "flatten_1 (Flatten)            |    convolution2d_5[0][0]            \n",
    "_______________________________|_____________________________________________________________________\n",
    "dense_1 (Dense)                |    flatten_1[0][0]                  \n",
    "_______________________________|_____________________________________________________________________\n",
    "dense_2 (Dense)                |    dense_1[0][0]                    \n",
    "_______________________________|_____________________________________________________________________\n",
    "dense_3 (Dense)                |    dense_2[0][0]                    \n",
    "_______________________________|_____________________________________________________________________\n",
    "dense_4 (Dense)                |    dense_3[0][0]                    \n",
    "====================================================================================================\n",
    "```\n",
    "\n",
    "(More details about this bellow.)\n",
    "\n",
    "#### 2. Attempts to reduce overfitting in the model\n",
    "\n",
    "I decided  to modify the model by applying regularization techniques like [Dropout](https://en.wikipedia.org/wiki/Dropout_(neural_networks)) of .1 only (due to low epoch).thendecided to keep the training epochs low: only three epochs.\n",
    "In addition to that, I split my sample data into training and validation data\n",
    "The model used an Adam optimizer, so the learning rate was not tuned manually\n",
    "\n",
    "#### 4. Appropriate training data\n",
    "\n",
    "Training data was chosen to keep the vehicle driving on the road. Also, the data provided by Udacity, I used the first track and second track data. The simulator provides three different images: center, left and right cameras. Each image was used to train the model.\n",
    "\n",
    "For details about how I created the training data, see the next section.\n",
    "\n",
    "### Model Architecture and Training Strategy\n",
    "\n",
    "#### 1. Solution Design Approach\n",
    "\n",
    "##### My first step was to try the [LeNet] (http://yann.lecun.com/exdb/lenet/) model with three epochs and the training data provided by Udacity. On the first track, the car went straight to the lake. I needed to do some pre-processing. A  `Lambda` layer was introduced to normalize the input images to zero means. This step allows the car to move a bit further, but it didn't get to the first turn. Another `Cropping` was introduced, and the first turn was almost there, but not quite.\n",
    "\n",
    "##### The second step was to use better  model: [nVidia Autonomous Car Group] (https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/) The only modification was to add a new\n",
    "\n",
    "##### layer at the end to have a single output as it was required. This time the car did its first complete track, but there \n",
    "#### was a place in the track where it passes over the \"dashed\" line. More data was needed. Augmented the data by adding the same image flipped with a negative angleIn addition to that, the left and right camera images where introduced with a correction factor on the angle to help the car go back to the lane, After this process, the car continues to have the same problem with the same \"dashed\" line.\n",
    "\n",
    "#### 2. Creation of the Training Set & Training Process\n",
    "\n",
    "To have more data, the following tracks were capture:\n",
    "\n",
    "- First track.\n",
    "  - One track driving forward partial driving.\n",
    "  - One track driving backward partial driving.\n",
    "- half second track driving \n",
    "\n",
    "All these data was used for training the model with three epochs. The data was shuffled randomly. The following picture shows the training:\n",
    "\n",
    "[Model Mean-square ](new_model_mse_loss.png)\n",
    "\n",
    "\n",
    "MSE image               <img src=\"new_model_mse_loss.png\"  width=\"200\"/>\n",
    "\n",
    "sample image 1          <img src=\"1.jpg\"  width=\"200\"/>\n",
    "sample image 2          <img src=\"2.jpg\"  width=\"200\"/>\n",
    "sample image 3          <img src=\"3.jpg\"  width=\"200\"/>\n",
    "recovery image 1        <img src=\"recovery1.jpg\"  width=\"200\"/>\n",
    "recovery image 2        <img src=\"recovery2.jpg\"  width=\"200\"/>\n",
    "\n",
    "sample image track2     <img src=\"track2.jpg\"  width=\"200\"/>\n",
    "\n",
    " \n",
    "After this training, the car was driving down the road all the time on the [first](run1.mp4) and in some part of second track \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:self_drive]",
   "language": "python",
   "name": "conda-env-self_drive-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
